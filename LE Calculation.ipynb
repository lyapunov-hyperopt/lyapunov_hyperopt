{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import dataloader as dl\n",
    "from models import RNNModel\n",
    "from training import *\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import time\n",
    "\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import lyapunov_test as lyap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  data/data.pkl ...\n",
      "Loading  data/vocab.pkl ...\n",
      "None\n",
      "Cutting off end of data so that it divides evenly\n",
      "Data load done! Number of data batches in train: 200, val: 25, test: 24\n"
     ]
    }
   ],
   "source": [
    "dcon = DataConfig('data', input_seq_length = 100, target_seq_length = 1, train_frac = 0.8, val_frac = 0.1, test_frac = 0.1, batch_size = 128)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model and Training Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "learning_rate = 0.002\n",
    "dropout = 0.1\n",
    "uni_param = 0.08\n",
    "batch_size = 128\n",
    "model_type = 'gru'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sch = torch.optim.lr_scheduler.MultiStepLR\n",
    "sch_params = {'milestones': range(10, 50), 'gamma': 0.95}\n",
    "max_epoch = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcon = ModelConfig(model_type, 1, hidden_size, dcon.input_size, dropout, 'uni', {'a': -uni_param, 'b':uni_param}, device, bias = False, id_init_param = 'b')\n",
    "tcon = TrainConfig('Models', batch_size, max_epoch, 'adam', learning_rate, {}, scheduler = sch, scheduler_params= sch_params, start_epoch = 0)\n",
    "fcon = FullConfig(dcon, tcon, mcon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(mcon).to(mcon.device)\n",
    "optimizer = tcon.get_optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models Using Hyperopt Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    fcon = space['config']\n",
    "    param = space['param']\n",
    "    fcon.model.init_params = {'a': -param, 'b':param}\n",
    "    model = RNNModel(fcon.model)\n",
    "    optimizer = fcon.train.get_optimizer(model.parameters())\n",
    "    train_loss, val_loss = train_model(fcon, model, optimizer, verbose = False, save_interval = 3)\n",
    "    return {\n",
    "        'loss': train_loss[-1],\n",
    "        'status': STATUS_OK,\n",
    "        'eval_time': time.time(),\n",
    "        'val_loss': val_loss\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Size: 64\n",
      "100%|██████████| 60/60 [55:06<00:00, 55.12s/trial, best loss: 1.9232112938165664]\n",
      "Hidden Size: 128\n",
      "100%|██████████| 60/60 [1:19:29<00:00, 79.49s/trial, best loss: 1.7544687151908875]\n",
      "Hidden Size: 256\n",
      "100%|██████████| 60/60 [2:04:22<00:00, 124.37s/trial, best loss: 1.530445828437805]  \n",
      "Hidden Size: 512\n",
      "100%|██████████| 60/60 [4:18:04<00:00, 258.08s/trial, best loss: 1.3131837475299835]  \n",
      "Hidden Size: 64\n",
      "100%|██████████| 60/60 [53:15<00:00, 53.25s/trial, best loss: 1.7973689597845077]\n",
      "Hidden Size: 128\n",
      "100%|██████████| 60/60 [1:06:41<00:00, 66.69s/trial, best loss: 1.6492356532812118]\n",
      "Hidden Size: 256\n",
      "100%|██████████| 60/60 [1:50:28<00:00, 110.47s/trial, best loss: 1.4638451838493347]\n",
      "Hidden Size: 512\n",
      "  2%|▏         | 1/60 [03:42<3:38:25, 222.13s/trial, best loss: 1.3793333268165588]"
     ]
    }
   ],
   "source": [
    "for model_type in ['lstm', 'gru']:\n",
    "    for hidden_size in [64, 128, 256, 512]:\n",
    "        print('Hidden Size: {}'.format(hidden_size))\n",
    "        trials = Trials()\n",
    "    #     trials = pkl.load(open('{}_trials_{}.p'.format(fcon.model.model_type, hidden_size), 'rb'))\n",
    "        mcon = ModelConfig(model_type, 1, hidden_size, dcon.input_size, dropout, 'uni', {'a': -uni_param, 'b':uni_param}, device, bias = False, id_init_param = 'b')\n",
    "        tcon = TrainConfig('Models', batch_size, max_epoch, 'adam', learning_rate, {}, scheduler = sch, scheduler_params= sch_params, start_epoch = 0)\n",
    "        fcon = FullConfig(dcon, tcon, mcon)\n",
    "\n",
    "        space = hp.choice('uni_param',[\n",
    "            {\n",
    "                'param': hp.quniform('param', .04, .24, .001),\n",
    "                'config': fcon\n",
    "            }    \n",
    "        ])\n",
    "\n",
    "\n",
    "        model = RNNModel(mcon).to(mcon.device)\n",
    "        optimizer = tcon.get_optimizer(model.parameters())\n",
    "        best = fmin(objective, \n",
    "                    space = space,\n",
    "                    algo = tpe.suggest,\n",
    "                    trials = trials,\n",
    "                    max_evals = 60\n",
    "                   )\n",
    "        pkl.dump(trials, open('{}_trials_{}.p'.format(fcon.model.model_type, hidden_size), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trials and calculate Lyapunov Exponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "le_batch_size = 10\n",
    "le_seq_length = 1000\n",
    "warmup = 0\n",
    "ON = 1\n",
    "\n",
    "fcon.model.hidden_size = hidden_size\n",
    "lcon = LyapConfig(le_batch_size, le_seq_length, ON_step = ON, warmup = warmup, one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials = pkl.load(open('trials_{}.p'.format(hidden_size), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = 15\n",
    "for hidden_size in [64, 128, 256, 512]:\n",
    "    print(hidden_size)\n",
    "    trials = pkl.load(open('{}_trials_{}.p'.format(fcon.model.model_type, hidden_size), 'rb'))\n",
    "    fcon.model.rnn_atts['hidden_size'] = hidden_size\n",
    "    lcon = LyapConfig(le_batch_size, le_seq_length, ON_step = ON, warmup = warmup, one_hot = True)\n",
    "    data = lcon.get_input(fcon)\n",
    "    for trial in trials:\n",
    "        uni_param = trial['misc']['vals']['param'][0]\n",
    "        fcon.model.init_params = {'a': -uni_param, 'b':uni_param}\n",
    "        ckpt = load_checkpoint(fcon, epoch)\n",
    "        model = ckpt[0].to(fcon.device)\n",
    "        LE_stats, _ = lcon.calc_lyap(data, model, fcon)\n",
    "        torch.save(LE_stats, 'LE_stats/{}_LE_stats_e{}.p'.format(fcon.name(), epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hidden_size in [64, 128, 256, 512]:\n",
    "    fcon.model.hidden_size = hidden_size\n",
    "    lcon = LyapConfig(le_batch_size, le_seq_length, ON_step = ON, warmup = warmup, one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcon.model.model_type = 'lstm'\n",
    "for hidden_size in [64, 128, 256, 512]:\n",
    "    fcon.model.rnn_atts['hidden_size'] = hidden_size\n",
    "    trials = pkl.load(open('{}_trials_{}.p'.format(fcon.model.model_type, hidden_size), 'rb'))\n",
    "    LE_tensor = torch.zeros((30, hidden_size))\n",
    "    LE_stds = torch.zeros((30, hidden_size))\n",
    "    for i, trial in enumerate(trials):\n",
    "        uni_param = trial['misc']['vals']['param'][0]\n",
    "        fcon.model.init_params = {'a': -uni_param, 'b':uni_param}\n",
    "        LE_tensor[i, :], LE_stds[i, :] = torch.load('LE_stats/{}_LE_stats_e{}.p'.format(fcon.name(), 15))\n",
    "    torch.save(LE_tensor, 'LE_stats/{}_{}_LEs.p'.format(fcon.model.model_type, hidden_size))\n",
    "    torch.save(LE_stds, 'LE_stats/{}_{}_LEerrors.p'.format(fcon.model.model_type, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcon.model.model_type = 'gru'\n",
    "torch.load('LE_stats/{}_LE_stats_e{}.p'.format(fcon.name(), 15))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcon.model.model_type = 'gru'\n",
    "for hidden_size in [64, 128, 256, 512]:\n",
    "    fcon.model.rnn_atts['hidden_size'] = hidden_size\n",
    "    trials = pkl.load(open('{}_trials_{}.p'.format(fcon.model.model_type, hidden_size), 'rb'))\n",
    "    final_tloss = torch.zeros((30))\n",
    "    vlosses = torch.zeros((30))\n",
    "    for i, trial in enumerate(trials):\n",
    "        uni_param = trial['misc']['vals']['param'][0]\n",
    "        fcon.model.init_params = {'a': -uni_param, 'b':uni_param}\n",
    "        _, _, train_loss, val_loss = load_checkpoint(fcon, fcon.train.max_epoch)\n",
    "        final_tloss[i] = train_loss[-1]\n",
    "        vlosses[i] = val_loss\n",
    "    torch.save(final_tloss, 'LE_stats/{}_{}_trainLoss.p'.format(fcon.model.model_type, hidden_size))\n",
    "    torch.save(vlosses, 'LE_stats/{}_{}_valLoss.p'.format(fcon.model.model_type, hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(vlosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'lstm'\n",
    "for hidden_size in [64, 128, 256, 512]:\n",
    "    fcon.model.rnn_atts['hidden_size'] = hidden_size\n",
    "    fcon.model.model_type = model_type\n",
    "    LEs = torch.load('LE_stats/{}_{}_LEs.p'.format(fcon.model.model_type, hidden_size))\n",
    "    LE_errors = torch.load('LE_stats/{}_{}_LEerrors.p'.format(fcon.model.model_type, hidden_size))\n",
    "    train_loss = torch.load('LE_stats/{}_{}_trainLoss.p'.format(fcon.model.model_type, hidden_size))\n",
    "    val_loss = torch.load('LE_stats/{}_{}_valLoss.p'.format(fcon.model.model_type, hidden_size))\n",
    "    plot_summary(val_loss, [0,1,4,2, 9, 21], LEs, LE_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "def plot_summary(val_losses, idcs, LEs, LE_errors):\n",
    "    plt.rc('font', family = 'serif')\n",
    "    plt.rc('xtick', labelsize = 'medium')\n",
    "    plt.rc('ytick', labelsize = 'medium')\n",
    "    fontsize = 12\n",
    "    hidden_size = LEs.shape[1]\n",
    "    fig= plt.figure(figsize = (6,3))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    # ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax_max = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "\n",
    "\n",
    "    idcs = torch.LongTensor(idcs)\n",
    "#     print(idcs)\n",
    "    val_lims = [torch.min(val_losses), torch.max(val_losses)]\n",
    "    plt.rc('ytick', labelsize = 'small')\n",
    "    plt.rc('xtick', labelsize = 'small')\n",
    "    axin1 = ax1.inset_axes([0.15, 0.1, 0.38, 0.38])\n",
    "\n",
    "    for i, idx in enumerate(idcs):\n",
    "        axin1.plot(range(0,10), LEs[idx, :10], '-o', markersize = 2.5, linewidth = .5, label = idx.item())\n",
    "        axin1.set_yticks([0, -.5])\n",
    "    #     axin1.set_ylim([-., 0])\n",
    "    axin1.plot([0, 10], [0, 0], 'white', linewidth = .5)\n",
    "\n",
    "    axin1.set_xlim([0,9])\n",
    "    axin1.yaxis.set_minor_locator(MultipleLocator(.1))\n",
    "    #     axin1.set_xlabel(i)\n",
    "    plt.rc('ytick', labelsize = 'medium')\n",
    "    plt.rc('xtick', labelsize = 'medium')\n",
    "    for idx in range(len(val_losses)):\n",
    "        ax1.scatter(range(0,hidden_size), LEs[idx, :], s = .5, color = 'grey', alpha = .1)\n",
    "    for i, idx in enumerate(idcs):\n",
    "        ax1.scatter(range(0,hidden_size), LEs[idx, :], s = 2, label = idx.item())\n",
    "    # plt.plot([0, 512], [0, 0], 'k--')\n",
    "    # ax1.set_title('(a)')\n",
    "    ax1.set_ylabel(r'$\\lambda_i$', fontsize = fontsize)\n",
    "    ax1.set_xlabel(r'$i$', fontsize = fontsize)\n",
    "    ax1.set_ylim([-8, 0])\n",
    "    ax1.set_xlim([0, hidden_size])\n",
    "    # plt.legend(title = 'Trial')\n",
    "    # plt.savefig(\"Trial Spectra.png\",bbox_inches=\"tight\",dpi=400, format = 'png')\n",
    "\n",
    "\n",
    "    x=  LEs[:, 0][idcs]\n",
    "    y = np.array(val_losses)[idcs]\n",
    "    ax_max.scatter(LEs[:,0], val_losses, color = 'gray', alpha = 0.4)\n",
    "    for i in range(x.shape[0]):\n",
    "        ax_max.scatter(x[i], y[i], s = 50)\n",
    "\n",
    "    # ax_max.set_title('(b)')\n",
    "    ax_max.set_xlabel(r' Max LE, $\\lambda_{max}$', fontsize  =12)\n",
    "    ax_max.set_ylabel('Validation Loss', fontsize = 12)\n",
    "    # ax3.scatter(slopes1, val_loss_mins, s= 20, edgecolors = 'k', facecolors = 'none')\n",
    "    # ax3.set_xlim([np.min(slopes1)-.0001, np.max(slopes1)+.0001]) \n",
    "    # ax3.set_xlabel('LE Slope', fontsize = fontsize)\n",
    "    # ax3.set_ylabel('Validation Loss', fontsize = fontsize)\n",
    "\n",
    "    # ax4.scatter(LE_avgs, val_loss_mins, s= 20, edgecolors = 'k', facecolors = 'none')\n",
    "    # ax4.set_xlabel('LE Mean', fontsize = fontsize)\n",
    "    # ax4.set_ylabel('Validation Loss', fontsize = fontsize)\n",
    "    plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=1.0)\n",
    "    # ax4.savefig(\"Mean_ValMin.png\",bbox_inches=\"tight\",dpi=400, format = 'png')\n",
    "#     plt.savefig(\"CharLE_Summary.png\",bbox_inches=\"tight\",dpi=400, format = 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(vlosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
